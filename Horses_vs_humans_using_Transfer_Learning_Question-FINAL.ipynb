{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz"
   },
   "outputs": [],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
    "                                include_top = False, # Remove dense layer before CONV layers\n",
    "                                weights = None) # Don't use default weights\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('acc')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_282 (Conv2D)             (None, 74, 74, 32)   864         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_282 (BatchN (None, 74, 74, 32)   96          conv2d_282[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 74, 74, 32)   0           batch_normalization_282[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_283 (Conv2D)             (None, 72, 72, 32)   9216        activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_283 (BatchN (None, 72, 72, 32)   96          conv2d_283[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 72, 72, 32)   0           batch_normalization_283[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_284 (Conv2D)             (None, 72, 72, 64)   18432       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_284 (BatchN (None, 72, 72, 64)   192         conv2d_284[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 72, 72, 64)   0           batch_normalization_284[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 35, 35, 64)   0           activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_285 (Conv2D)             (None, 35, 35, 80)   5120        max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_285 (BatchN (None, 35, 35, 80)   240         conv2d_285[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 35, 35, 80)   0           batch_normalization_285[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_286 (Conv2D)             (None, 33, 33, 192)  138240      activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_286 (BatchN (None, 33, 33, 192)  576         conv2d_286[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 33, 33, 192)  0           batch_normalization_286[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 192)  0           activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_290 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_290 (BatchN (None, 16, 16, 64)   192         conv2d_290[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 16, 16, 64)   0           batch_normalization_290[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_288 (Conv2D)             (None, 16, 16, 48)   9216        max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_291 (Conv2D)             (None, 16, 16, 96)   55296       activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_288 (BatchN (None, 16, 16, 48)   144         conv2d_288[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_291 (BatchN (None, 16, 16, 96)   288         conv2d_291[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 16, 16, 48)   0           batch_normalization_288[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 16, 16, 96)   0           batch_normalization_291[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_27 (AveragePo (None, 16, 16, 192)  0           max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_287 (Conv2D)             (None, 16, 16, 64)   12288       max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_289 (Conv2D)             (None, 16, 16, 64)   76800       activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_292 (Conv2D)             (None, 16, 16, 96)   82944       activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_293 (Conv2D)             (None, 16, 16, 32)   6144        average_pooling2d_27[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_287 (BatchN (None, 16, 16, 64)   192         conv2d_287[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_289 (BatchN (None, 16, 16, 64)   192         conv2d_289[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_292 (BatchN (None, 16, 16, 96)   288         conv2d_292[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_293 (BatchN (None, 16, 16, 32)   96          conv2d_293[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 16, 16, 64)   0           batch_normalization_287[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 16, 16, 64)   0           batch_normalization_289[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 16, 16, 96)   0           batch_normalization_292[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 16, 16, 32)   0           batch_normalization_293[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_287[0][0]             \n",
      "                                                                 activation_289[0][0]             \n",
      "                                                                 activation_292[0][0]             \n",
      "                                                                 activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_297 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_297 (BatchN (None, 16, 16, 64)   192         conv2d_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 16, 16, 64)   0           batch_normalization_297[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_295 (Conv2D)             (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_298 (Conv2D)             (None, 16, 16, 96)   55296       activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_295 (BatchN (None, 16, 16, 48)   144         conv2d_295[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_298 (BatchN (None, 16, 16, 96)   288         conv2d_298[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 16, 16, 48)   0           batch_normalization_295[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 16, 16, 96)   0           batch_normalization_298[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_28 (AveragePo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_294 (Conv2D)             (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_296 (Conv2D)             (None, 16, 16, 64)   76800       activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_299 (Conv2D)             (None, 16, 16, 96)   82944       activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_300 (Conv2D)             (None, 16, 16, 64)   16384       average_pooling2d_28[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_294 (BatchN (None, 16, 16, 64)   192         conv2d_294[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_296 (BatchN (None, 16, 16, 64)   192         conv2d_296[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_299 (BatchN (None, 16, 16, 96)   288         conv2d_299[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_300 (BatchN (None, 16, 16, 64)   192         conv2d_300[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 16, 16, 64)   0           batch_normalization_294[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 16, 16, 64)   0           batch_normalization_296[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 16, 16, 96)   0           batch_normalization_299[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 16, 16, 64)   0           batch_normalization_300[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_294[0][0]             \n",
      "                                                                 activation_296[0][0]             \n",
      "                                                                 activation_299[0][0]             \n",
      "                                                                 activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_304 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_304 (BatchN (None, 16, 16, 64)   192         conv2d_304[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 16, 16, 64)   0           batch_normalization_304[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_302 (Conv2D)             (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_305 (Conv2D)             (None, 16, 16, 96)   55296       activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_302 (BatchN (None, 16, 16, 48)   144         conv2d_302[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_305 (BatchN (None, 16, 16, 96)   288         conv2d_305[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 16, 16, 48)   0           batch_normalization_302[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 16, 16, 96)   0           batch_normalization_305[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_29 (AveragePo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_301 (Conv2D)             (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_303 (Conv2D)             (None, 16, 16, 64)   76800       activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_306 (Conv2D)             (None, 16, 16, 96)   82944       activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_307 (Conv2D)             (None, 16, 16, 64)   18432       average_pooling2d_29[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_301 (BatchN (None, 16, 16, 64)   192         conv2d_301[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_303 (BatchN (None, 16, 16, 64)   192         conv2d_303[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_306 (BatchN (None, 16, 16, 96)   288         conv2d_306[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_307 (BatchN (None, 16, 16, 64)   192         conv2d_307[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 16, 16, 64)   0           batch_normalization_301[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 16, 16, 64)   0           batch_normalization_303[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 16, 16, 96)   0           batch_normalization_306[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 16, 16, 64)   0           batch_normalization_307[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_301[0][0]             \n",
      "                                                                 activation_303[0][0]             \n",
      "                                                                 activation_306[0][0]             \n",
      "                                                                 activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_309 (Conv2D)             (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_309 (BatchN (None, 16, 16, 64)   192         conv2d_309[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 16, 16, 64)   0           batch_normalization_309[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_310 (Conv2D)             (None, 16, 16, 96)   55296       activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_310 (BatchN (None, 16, 16, 96)   288         conv2d_310[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 16, 16, 96)   0           batch_normalization_310[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_308 (Conv2D)             (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_311 (Conv2D)             (None, 7, 7, 96)     82944       activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_308 (BatchN (None, 7, 7, 384)    1152        conv2d_308[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_311 (BatchN (None, 7, 7, 96)     288         conv2d_311[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 7, 7, 384)    0           batch_normalization_308[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 7, 7, 96)     0           batch_normalization_311[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_308[0][0]             \n",
      "                                                                 activation_311[0][0]             \n",
      "                                                                 max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_316 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_316 (BatchN (None, 7, 7, 128)    384         conv2d_316[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_316 (Activation)     (None, 7, 7, 128)    0           batch_normalization_316[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_317 (Conv2D)             (None, 7, 7, 128)    114688      activation_316[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_317 (BatchN (None, 7, 7, 128)    384         conv2d_317[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_317 (Activation)     (None, 7, 7, 128)    0           batch_normalization_317[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_313 (Conv2D)             (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_318 (Conv2D)             (None, 7, 7, 128)    114688      activation_317[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_313 (BatchN (None, 7, 7, 128)    384         conv2d_313[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_318 (BatchN (None, 7, 7, 128)    384         conv2d_318[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_313 (Activation)     (None, 7, 7, 128)    0           batch_normalization_313[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_318 (Activation)     (None, 7, 7, 128)    0           batch_normalization_318[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_314 (Conv2D)             (None, 7, 7, 128)    114688      activation_313[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_319 (Conv2D)             (None, 7, 7, 128)    114688      activation_318[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_314 (BatchN (None, 7, 7, 128)    384         conv2d_314[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_319 (BatchN (None, 7, 7, 128)    384         conv2d_319[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_314 (Activation)     (None, 7, 7, 128)    0           batch_normalization_314[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_319 (Activation)     (None, 7, 7, 128)    0           batch_normalization_319[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_30 (AveragePo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_312 (Conv2D)             (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_315 (Conv2D)             (None, 7, 7, 192)    172032      activation_314[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_320 (Conv2D)             (None, 7, 7, 192)    172032      activation_319[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_321 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_30[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_312 (BatchN (None, 7, 7, 192)    576         conv2d_312[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_315 (BatchN (None, 7, 7, 192)    576         conv2d_315[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_320 (BatchN (None, 7, 7, 192)    576         conv2d_320[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_321 (BatchN (None, 7, 7, 192)    576         conv2d_321[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_312 (Activation)     (None, 7, 7, 192)    0           batch_normalization_312[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_315 (Activation)     (None, 7, 7, 192)    0           batch_normalization_315[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_320 (Activation)     (None, 7, 7, 192)    0           batch_normalization_320[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_321 (Activation)     (None, 7, 7, 192)    0           batch_normalization_321[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_312[0][0]             \n",
      "                                                                 activation_315[0][0]             \n",
      "                                                                 activation_320[0][0]             \n",
      "                                                                 activation_321[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_326 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_326 (BatchN (None, 7, 7, 160)    480         conv2d_326[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_326 (Activation)     (None, 7, 7, 160)    0           batch_normalization_326[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_327 (Conv2D)             (None, 7, 7, 160)    179200      activation_326[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_327 (BatchN (None, 7, 7, 160)    480         conv2d_327[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_327 (Activation)     (None, 7, 7, 160)    0           batch_normalization_327[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_323 (Conv2D)             (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_328 (Conv2D)             (None, 7, 7, 160)    179200      activation_327[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_323 (BatchN (None, 7, 7, 160)    480         conv2d_323[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_328 (BatchN (None, 7, 7, 160)    480         conv2d_328[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_323 (Activation)     (None, 7, 7, 160)    0           batch_normalization_323[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_328 (Activation)     (None, 7, 7, 160)    0           batch_normalization_328[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_324 (Conv2D)             (None, 7, 7, 160)    179200      activation_323[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_329 (Conv2D)             (None, 7, 7, 160)    179200      activation_328[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_324 (BatchN (None, 7, 7, 160)    480         conv2d_324[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_329 (BatchN (None, 7, 7, 160)    480         conv2d_329[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_324 (Activation)     (None, 7, 7, 160)    0           batch_normalization_324[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_329 (Activation)     (None, 7, 7, 160)    0           batch_normalization_329[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_31 (AveragePo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_322 (Conv2D)             (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_325 (Conv2D)             (None, 7, 7, 192)    215040      activation_324[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_330 (Conv2D)             (None, 7, 7, 192)    215040      activation_329[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_331 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_31[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_322 (BatchN (None, 7, 7, 192)    576         conv2d_322[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_325 (BatchN (None, 7, 7, 192)    576         conv2d_325[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_330 (BatchN (None, 7, 7, 192)    576         conv2d_330[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_331 (BatchN (None, 7, 7, 192)    576         conv2d_331[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_322 (Activation)     (None, 7, 7, 192)    0           batch_normalization_322[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_325 (Activation)     (None, 7, 7, 192)    0           batch_normalization_325[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_330 (Activation)     (None, 7, 7, 192)    0           batch_normalization_330[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_331 (Activation)     (None, 7, 7, 192)    0           batch_normalization_331[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_322[0][0]             \n",
      "                                                                 activation_325[0][0]             \n",
      "                                                                 activation_330[0][0]             \n",
      "                                                                 activation_331[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_336 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_336 (BatchN (None, 7, 7, 160)    480         conv2d_336[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_336 (Activation)     (None, 7, 7, 160)    0           batch_normalization_336[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_337 (Conv2D)             (None, 7, 7, 160)    179200      activation_336[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_337 (BatchN (None, 7, 7, 160)    480         conv2d_337[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_337 (Activation)     (None, 7, 7, 160)    0           batch_normalization_337[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_333 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_338 (Conv2D)             (None, 7, 7, 160)    179200      activation_337[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_333 (BatchN (None, 7, 7, 160)    480         conv2d_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_338 (BatchN (None, 7, 7, 160)    480         conv2d_338[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_333 (Activation)     (None, 7, 7, 160)    0           batch_normalization_333[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_338 (Activation)     (None, 7, 7, 160)    0           batch_normalization_338[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_334 (Conv2D)             (None, 7, 7, 160)    179200      activation_333[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_339 (Conv2D)             (None, 7, 7, 160)    179200      activation_338[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_334 (BatchN (None, 7, 7, 160)    480         conv2d_334[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_339 (BatchN (None, 7, 7, 160)    480         conv2d_339[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_334 (Activation)     (None, 7, 7, 160)    0           batch_normalization_334[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_339 (Activation)     (None, 7, 7, 160)    0           batch_normalization_339[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_32 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_332 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_335 (Conv2D)             (None, 7, 7, 192)    215040      activation_334[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_340 (Conv2D)             (None, 7, 7, 192)    215040      activation_339[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_341 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_32[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_332 (BatchN (None, 7, 7, 192)    576         conv2d_332[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_335 (BatchN (None, 7, 7, 192)    576         conv2d_335[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_340 (BatchN (None, 7, 7, 192)    576         conv2d_340[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_341 (BatchN (None, 7, 7, 192)    576         conv2d_341[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_332 (Activation)     (None, 7, 7, 192)    0           batch_normalization_332[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_335 (Activation)     (None, 7, 7, 192)    0           batch_normalization_335[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_340 (Activation)     (None, 7, 7, 192)    0           batch_normalization_340[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_341 (Activation)     (None, 7, 7, 192)    0           batch_normalization_341[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_332[0][0]             \n",
      "                                                                 activation_335[0][0]             \n",
      "                                                                 activation_340[0][0]             \n",
      "                                                                 activation_341[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_346 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_346 (BatchN (None, 7, 7, 192)    576         conv2d_346[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_346 (Activation)     (None, 7, 7, 192)    0           batch_normalization_346[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_347 (Conv2D)             (None, 7, 7, 192)    258048      activation_346[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_347 (BatchN (None, 7, 7, 192)    576         conv2d_347[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_347 (Activation)     (None, 7, 7, 192)    0           batch_normalization_347[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_343 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 7, 7, 192)    258048      activation_347[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_343 (BatchN (None, 7, 7, 192)    576         conv2d_343[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_348 (BatchN (None, 7, 7, 192)    576         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_343 (Activation)     (None, 7, 7, 192)    0           batch_normalization_343[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_348 (Activation)     (None, 7, 7, 192)    0           batch_normalization_348[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_344 (Conv2D)             (None, 7, 7, 192)    258048      activation_343[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 7, 7, 192)    258048      activation_348[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_344 (BatchN (None, 7, 7, 192)    576         conv2d_344[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_349 (BatchN (None, 7, 7, 192)    576         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_344 (Activation)     (None, 7, 7, 192)    0           batch_normalization_344[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_349 (Activation)     (None, 7, 7, 192)    0           batch_normalization_349[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_33 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_342 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_345 (Conv2D)             (None, 7, 7, 192)    258048      activation_344[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 7, 7, 192)    258048      activation_349[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_33[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_342 (BatchN (None, 7, 7, 192)    576         conv2d_342[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_345 (BatchN (None, 7, 7, 192)    576         conv2d_345[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_350 (BatchN (None, 7, 7, 192)    576         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_351 (BatchN (None, 7, 7, 192)    576         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_342 (Activation)     (None, 7, 7, 192)    0           batch_normalization_342[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_345 (Activation)     (None, 7, 7, 192)    0           batch_normalization_345[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_350 (Activation)     (None, 7, 7, 192)    0           batch_normalization_350[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_351 (Activation)     (None, 7, 7, 192)    0           batch_normalization_351[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_342[0][0]             \n",
      "                                                                 activation_345[0][0]             \n",
      "                                                                 activation_350[0][0]             \n",
      "                                                                 activation_351[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1024)         38536192    flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            1025        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 38,537,217\n",
      "Non-trainable params: 8,975,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "#callbacks = myCallback()\n",
    "model = Model( pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join('/tmp/training/horses')\n",
    "train_humans_dir = os.path.join('/tmp/training/humans')\n",
    "validation_horses_dir = os.path.join('/tmp/validation/horses')\n",
    "validation_humans_dir = os.path.join('/tmp/validation/humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    batch_size = 20,\n",
    "                                                    class_mode = 'binary', \n",
    "                                                    target_size = (150, 150))     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory( validation_dir,\n",
    "                                                          batch_size  = 20,\n",
    "                                                          class_mode  = 'binary', \n",
    "                                                          target_size = (150, 150))\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.0949 - accuracy: 0.9666 - val_loss: 0.0105 - val_accuracy: 0.9958\n",
      "Epoch 2/3\n",
      "50/50 [==============================] - 50s 1s/step - loss: 0.1089 - accuracy: 0.9676 - val_loss: 0.0141 - val_accuracy: 0.9917\n",
      "Epoch 3/3\n",
      "50/50 [==============================] - 51s 1s/step - loss: 0.0645 - accuracy: 0.9767 - val_loss: 0.0635 - val_accuracy: 0.9875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "#callbacks = myCallback()\n",
    "history = model.fit_generator(train_generator,\n",
    "                              validation_data = validation_generator,\n",
    "                              steps_per_epoch = 50,\n",
    "                              epochs = 3,\n",
    "                              validation_steps = 12,\n",
    "                              verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
